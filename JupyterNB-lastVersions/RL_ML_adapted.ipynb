{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a569a5a8-bd60-4e8a-b5e8-9edc94062e7d",
   "metadata": {},
   "source": [
    "## RL Mars Lander from Lunar Lander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225629c-fd67-4b3b-8f8d-e52d8d291063",
   "metadata": {},
   "source": [
    "From Mars Lander - graphics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "547fe3e9-e384-46ab-95e3-aa06d46d7efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interactive  # what is ipywidgets - slider\n",
    "from matplotlib import rcParams \n",
    "from numpy.linalg import norm\n",
    "from numpy.random import randint\n",
    "from mpl_toolkits import mplot3d #added for 3D plotting\n",
    "from scipy.optimize import minimize   # for minimising landing speed\n",
    "from ipywidgets import interactive \n",
    "from matplotlib import rcParams  \n",
    "\n",
    "rcParams['figure.figsize'] = (10, 8)\n",
    "\n",
    "# add any imports necessary for RL of LL code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "954130d1-b0db-4f80-b3f5-27751e40b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_surface():\n",
    "    surfaceN = randint(5, 15)\n",
    "    land = np.zeros((surfaceN, 2), dtype=int)\n",
    "    \n",
    "    # Ensure there's a flat landing site at least 1000m long\n",
    "    landing_site = randint(1, surfaceN-1)\n",
    "    land[landing_site, 0] = randint(2000, 5000)\n",
    "    land[landing_site+1, 0] = min(land[landing_site, 0] + randint(1000, 2000), 6999)\n",
    "    land[landing_site+1, 1] = land[landing_site, 1] = randint(1, 1500)\n",
    "    \n",
    "    # Fill in the rest of the terrain\n",
    "    for i in range(landing_site):\n",
    "        land[i, 0] = (land[landing_site, 0] / landing_site) * i\n",
    "        land[i, 1] = randint(0, 1500)\n",
    "    \n",
    "    for i in range(landing_site + 2, surfaceN):\n",
    "        land[i, 0] = (land[landing_site + 1, 0] + \n",
    "                      (7000 - land[landing_site + 1, 0]) / len(land[landing_site + 2:]) * \n",
    "                      (i - (landing_site + 1)))\n",
    "        land[i, 1] = randint(0, 1500)\n",
    "    \n",
    "    # impose boundary conditions\n",
    "    land[0, 0] = 0\n",
    "    land[-1, 0] = 6999\n",
    "\n",
    "    return land, landing_site\n",
    "\n",
    "def plot_surface(land, landing_site):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(land[:landing_site+1, 0], land[:landing_site+1, 1], 'k-')\n",
    "    ax.plot(land[landing_site+1:, 0], land[landing_site+1:, 1], 'k-')\n",
    "    ax.plot([land[landing_site, 0], land[landing_site+1, 0]], \n",
    "             [land[landing_site, 1], land[landing_site+1, 1]], 'k--')\n",
    "    ax.set_xlim(0, 7000)\n",
    "    ax.set_ylim(0, 16000) # HERE was 13000\n",
    "    return ax\n",
    "\n",
    "def plot_lander(land, landing_site, X, thrust=None, animate=False, step=10):\n",
    "    if animate:\n",
    "        def plot_frame(n=len(X)-1):\n",
    "            ax = plot_surface(land, landing_site)\n",
    "            ax.plot(X[:n, 0], X[:n, 1], 'b--')      # trajectory of lander\n",
    "            ax.plot(X[n, 0], X[n, 1], 'k^', ms=20) # lander (color was b) , what is ^?\n",
    "            if thrust is not None:\n",
    "                ax.plot([X[n, 0], X[n, 0] - 100*thrust[n, 0]],\n",
    "                        [X[n, 1] - 100., X[n, 1] - 100. - 100*thrust[n, 1]], \n",
    "                       'r-', lw=10)\n",
    "        return interactive(plot_frame, n=(0, len(X), step)) #slider\n",
    "    else:\n",
    "        ax = plot_surface(land, landing_site) \n",
    "        ax.plot(X[:, 0], X[:, 1], 'b--')\n",
    "        ax.plot(X[-1, 0], X[-1, 1], 'b^')\n",
    "        return ax\n",
    "\n",
    "def interpolate_surface(land, x):\n",
    "    i,  = np.argwhere(land[:, 0] < x)[-1] # segment containing x is [i, i+1]\n",
    "    m = (land[i+1, 1] - land[i, 1])/(land[i+1, 0] - land[i, 0]) # gradient\n",
    "    x1, y1 = land[i, :] # point on line with eqn. y - y1 = m(x - x1) \n",
    "    return m*(x - x1) + y1\n",
    "\n",
    "#np.random.seed(20) # seed random number generator for reproducible results\n",
    "land, landing_site = mars_surface()\n",
    "#plot_surface(land, landing_site);\n",
    "\n",
    "\n",
    "def height(land, X):\n",
    "    return X[1] - interpolate_surface(land, X[0]) #1 in X[1] points to the vertical position y of the lander\n",
    "\n",
    "assert abs(height(land, [1, land[0, 1]])) < 100.0 # height when on surface left edge should be close to zero\n",
    "assert abs(height(land, [6999, land[-1, 1]])) < 100.0 # height when on surface at right edge should be close to zero\n",
    "\n",
    "_land, _landing_site = mars_surface()\n",
    "\n",
    "def _height(_land, X):\n",
    "    return X[1] - interpolate_surface(_land, X[0])\n",
    "\n",
    "points = np.zeros((10, 2))\n",
    "points[:, 0] = randint(0, 7000, size=10)\n",
    "points[:, 1] = randint(0, 16000, size=10)\n",
    "for i in range(10):\n",
    "    assert abs(height(_land, points[i, :]) - _height(_land, points[i, :])) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd05540-b5a6-41aa-a7c0-c17e9e0bd2bc",
   "metadata": {},
   "source": [
    "## Reinforcement Learning code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "24b96386-1119-48b5-95e5-34e76b17b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML step adapted: \n",
    "\n",
    "\n",
    "def step(i,X,V,power,prev_shaping,total_reward):   # eliminated self - need to pass necessary variables  # elminated action ! not as ML and doesn't involve rewards\n",
    "    \n",
    "    # what args need to be given ? X, V\n",
    "    \n",
    "        \"\"\"\n",
    "    returns:\n",
    "         s (list): The states\n",
    "         r: the reward for that step\n",
    "         done: True or False\n",
    "    \"\"\"\n",
    "        #action = np.clip(action, -1, +1).astype(np.float32) # .clip(a, a_min, a_max) ; Given an interval, values outside the interval are clipped to the interval edges\n",
    " \n",
    "        state = [\n",
    "            X[0],              # s[0] is the horizontal coordinate\n",
    "            X[1],              # s[1] is the vertical coordinate\n",
    "            V[0],              # s[2] is the horizontal speed\n",
    "            V[1],              # s[3] is the vertical speed\n",
    "            #lander.angle, # s[4] is the angle              #DON'T HAVE THIS !! rotate is the angle that we SHOULD make\n",
    "            #20.0 * lander.angularVelocity / FPS, # s[5] is the angular speed   #DON'T HAVE THIS !!\n",
    "        ]\n",
    "        assert len(state) == 4 # should be 6 with angle and angular speed\n",
    "        \n",
    "        ## add fuel !\n",
    "\n",
    "        reward = 0\n",
    "        shaping = (  # for rewards\n",
    "            -100 * np.sqrt(state[0] * state[0] + state[1] * state[1]) # Magnitude of position vectors\n",
    "            - 100 * np.sqrt(state[2] * state[2] + state[3] * state[3])  # Magnitude of velocity vectors\n",
    "            #- 100 * abs(state[4])\n",
    "        )  \n",
    "         \n",
    "        if prev_shaping is not None:# from reset function, need it? put it in demo_heurisic?\n",
    "            reward = shaping - prev_shaping         \n",
    "        prev_shaping = shaping\n",
    "\n",
    "        reward -= (\n",
    "            power * 0.30   # was m_power / add ML fuel consumption ?          # might need to choose more appropriate number  #power or thrust?\n",
    "        )  # less fuel spent is better, about -30 for heuristic landing\n",
    "\n",
    "        \n",
    "        return np.array(state, dtype=np.float32), reward#, done, {}  Â \n",
    "        #eliminated done (in simulate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "135645cc-98b7-4145-8d30-e0a1ead69e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML heuristic adapted:  # REPLACE BY SIMULATE?\n",
    "\n",
    "\n",
    "#def heuristic(s):    # REPLACE BY SIMULATE? (name it heuristic autopilot)? # eliminated environment from arg\n",
    "\"\"\"\n",
    "        env (erased): \n",
    "        s (list): The state. Attributes:\n",
    "                  s[0] is the horizontal coordinate\n",
    "                  s[1] is the vertical coordinate\n",
    "                  s[2] is the horizontal speed\n",
    "                  s[3] is the vertical speed\n",
    "                  s[4] is the angle\n",
    "                  s[5] is the angular speed \n",
    "                  Could add extra states: fuel remaining\n",
    "    returns:\n",
    "         a: The heuristic to be fed into the step function defined above to determine the next step and reward.\n",
    "\"\"\"\n",
    "    \n",
    "    #return a\n",
    "\n",
    "\n",
    "g = 3.711 # m/s^2 , gravity on Mars\n",
    "TSFC = 0.0003 # kg/(N*s)\n",
    "# fuel = 400 kg\n",
    "Dc = 6.3525 # drag force as a function of velocity\n",
    "\n",
    "def heuristic_simulation(X0, V0, land, landing_site, \n",
    "             fuel=400, dt=0.1, Nstep=1000, \n",
    "             autopilot=None, print_interval=100, parameters=None, parachute=None,prev_shaping = None,total_reward = 0):\n",
    "    \n",
    "    n = len(X0)       # number of degrees of freedom (2 here)\n",
    "    X = X0.copy()     # current position\n",
    "    V = np.array(V0).astype(float)  #was X0.copy()     # current velocity\n",
    "    Xs = np.zeros((Nstep, n)) # position history (trajectory) \n",
    "    Vs = np.zeros((Nstep, n)) # velocity history\n",
    "    thrust = np.zeros((Nstep, n)) # thrust history\n",
    "    drag = np.zeros((Nstep, n)) # drag history\n",
    "    \n",
    "    angle = np.zeros((Nstep, n)) # should be 1 instead of n?\n",
    "    \n",
    "    success = False\n",
    "    fuel_warning_printed = False\n",
    "    rotate = randint(-90, 90)            # degrees, initial angle random (heading alignment phase)\n",
    "    power = 0            # m/s^2, initial thrust power  \n",
    "    \n",
    "    e_prev = np.zeros(Nstep) # error history   \n",
    "\n",
    "    for i in range(Nstep):\n",
    "        Xs[i, :] = X     # Store positions\n",
    "        Vs[i, :] = V     # Store velocities\n",
    "        \n",
    "        if autopilot is not None:\n",
    "            \n",
    "            rotate, power, parachute,total_reward = autopilot(i, X, V, fuel, rotate, power, parameters, parachute,dt,e_prev,Nstep,prev_shaping,total_reward)\n",
    "            assert abs(rotate) <= 90\n",
    "            assert 0 <= power <= 12000\n",
    "        \n",
    "            rotate_rad = rotate * np.pi / 180.0 # degrees to radians\n",
    "            thrust[i, :] = power * np.array([np.sin(rotate_rad), \n",
    "                                             np.cos(rotate_rad)])\n",
    "            if fuel <= 0: \n",
    "                if not fuel_warning_printed:\n",
    "                    print(\"Fuel empty! Setting thrust to zero\")\n",
    "                    fuel_warning_printed = True\n",
    "                thrust[i, :] = 0\n",
    "            else:\n",
    "                fuel -= TSFC * power * dt\n",
    "                \n",
    "        m = 2600 + fuel  #kg , Mass of Lander + Rover + fuel  # fuel Mass loss\n",
    "        \n",
    "        if parachute == 0:\n",
    "            # no Drag                                               \n",
    "            drag[i, :] = 0               \n",
    "        else: # parachute == 1\n",
    "            # Drag - Parachute deployed  \n",
    "            drag[i, :] = -Dc*np.linalg.norm(V)*V                             \n",
    "            # linalg.norm(x) => Matrix or vector norm\n",
    "        \n",
    "        A = np.array([0, -g]) + thrust[i, :]/m + drag[i, :]/m\n",
    "                                   \n",
    "        V += A * dt                          # update velocities\n",
    "        X += V * dt                          # update positions\n",
    "        # calculate angle (not the same as how much we want the lander to rotate)\n",
    "        #angle = np.rad2deg(np.arctan(np.linalg.norm(V[:,0])/np.linalg.norm(V[:,1]))); # not sure at all\n",
    "        \n",
    "        \n",
    "        \n",
    "        if i % print_interval == 0: \n",
    "            print(f\"i={i:03d} X=[{X[0]:8.3f} {X[1]:8.3f}] V=[{V[0]:8.3f} {V[1]:8.3f}]\" # angle={angle:8.3f}\n",
    "                  f\" thrust=[{thrust[i, 0]:8.3f} {thrust[i, 1]:8.3f}] fuel={fuel:8.3f} rotate={rotate:8.3f} parachute={parachute:8.3f}\") \n",
    "        \n",
    "       \n",
    "        done = False  #needed?\n",
    "        # check for safe or crash landing\n",
    "        \n",
    "        \n",
    "        if X[1] < interpolate_surface(land, X[0]):\n",
    "            if not (land[landing_site, 0] <= X[0] and X[0] <= land[landing_site + 1, 0]):\n",
    "                print(\"crash! did not land on flat ground!\")\n",
    "                reward = -100\n",
    "                done = True\n",
    "            elif rotate != 0:\n",
    "                print(\"crash! did not land in a vertical position (tilt angle = 0 degrees)\")\n",
    "                reward = -100\n",
    "                done = True\n",
    "            elif abs(V[1]) >= 20: #was 40\n",
    "                print(\"crash! vertical speed must be limited (<20m/s in absolute value), got \", abs(V[1]))\n",
    "                reward = -100\n",
    "                done = True\n",
    "            elif abs(V[0]) >= 10: #was 20\n",
    "                print(\"crash! horizontal speed must be limited (<10m/s in absolute value), got \", abs(V[0]))\n",
    "                reward = -100\n",
    "                done = True\n",
    "            else:\n",
    "                print(\"safe landing - well done!\")\n",
    "                success = True\n",
    "                reward = +100\n",
    "                done = True\n",
    "            Nstep = i\n",
    "            break # in demo_heuristic_lander function\n",
    "                 \n",
    "    \n",
    "    return Xs[:Nstep,:], Vs[:Nstep,:], thrust[:Nstep,:], success, fuel, rotate, parachute,done, total_reward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "610e98fa-d4a4-4e2f-9378-da3a8b34265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportional_autopilot(i, X, V, fuel, rotate, power,parameters, parachute, dt, e_prev, Nstep,prev_shaping,total_reward):\n",
    "    K_v,K_p,K_h,K_i,K_d = parameters\n",
    "    \n",
    "    \n",
    "    c_v = 10.0 # target landing speed, m/s #c vertical\n",
    "    c_h = 0 #c horizontal and vertical #trade-off for rotation to go back to 0\n",
    "    \n",
    "    # Height from landing platform - CORRECTION -from landing platform , not irregular mars surface !\n",
    "    h = X[1]-land[landing_site, 1]; # was: height(land, X)\n",
    "    \n",
    "    # Horizontal displacement\n",
    "    Xtarget = (land[landing_site+1, 0] + land[landing_site, 0]) // 2 \n",
    "    dist = (Xtarget-X[0])  #X[i,0], pass the history of X (same for V)\n",
    "\n",
    "    rotate = np.rad2deg(np.arctan2(dist,h-2000))   \n",
    "    \n",
    "    # rough method to avoid 'did not land in a vertical position' error:\n",
    "    if h<2000:\n",
    "        rotate = 0\n",
    "      \n",
    "    # Combine vertical & horizontal errors\n",
    "    v_target_vert = -(c_v + K_v*(h-2000));\n",
    "    v_target_horz = abs(c_h+K_h*dist)\n",
    "    v_err_vert = abs(v_target_vert - V[1])\n",
    "    v_err_horz = abs(v_target_horz - V[0])\n",
    "    e =  v_err_vert + v_err_horz;\n",
    "    \n",
    "    e_d = 0\n",
    "    if i>0:\n",
    "        e_d = K_d*((e - e_prev[i-1])/dt)\n",
    "        \n",
    "    e_prev[i] = e     # Store error\n",
    "    \n",
    "    Pout = K_p*(e + e_d + K_i*(e_prev.sum()*dt)) \n",
    "    \n",
    "    power = min(max(Pout, 0.0), 12000.0)   # max thrust\n",
    "    \n",
    "    if h > 10000:\n",
    "        parachute = 0 \n",
    "    else:\n",
    "        parachute = 1 #open parachute\n",
    "    \n",
    "    # call to funtion 2\n",
    "    s, r = step(i,X,V,power,prev_shaping,total_reward)  #eliminated done, in simulation\n",
    "    total_reward += r\n",
    "    \n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f'total_reward={total_reward:8.3f} e={e:8.3f} power={power:8.3f}')     #K_p={K_p:8.3f} K_h={K_h:8.3f} K_v={K_v:8.3f} K_i={K_i:8.3f} K_d={K_d:8.3f}\n",
    "    return (rotate, power, parachute,total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "050b1195-e995-4a93-8eab-f68734507687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML demo_heuristic adapted:\n",
    "\n",
    "\n",
    "def demo_heuristic_lander(render=False): # testing equivalent , replace render\n",
    "    \n",
    "    total_reward = 0  #initialisation\n",
    "    steps = 0\n",
    "    s = None # ? (need to initialise states? or call step function) #Â bef: env.reset(seed=seed)\n",
    "    #prev_shaping = None\n",
    "    \n",
    "    \n",
    "    while True: # from testing: demo_heuristic_lander(LunarLander(), render=True)\n",
    "    \n",
    "        # call to funtion 1 - ML testing lines !!\n",
    "        \n",
    "        land, landing_site = mars_surface()\n",
    "        K_p= 50.000 ; K_h= 0.001 ; K_v= 0.005 ; K_i= 0.005 ; K_d= 75.000\n",
    "\n",
    "        iterations = 1\n",
    "        for i in list(range(iterations)):\n",
    "            X0 = [randint(2000, 5000), randint(15000, 16000)] \n",
    "            V0 = [randint(-50,50), randint(-500,-300)]\n",
    "            try:\n",
    "                Xs, Vs, thrust, success, fuel, rotate, parachute,done,total_reward = heuristic_simulation(X0, V0, land, landing_site, dt=0.1, Nstep=3500, \n",
    "                                                    autopilot=proportional_autopilot, fuel=400,parameters=[K_v,K_p,K_h,K_i,K_d],parachute=None,prev_shaping = None,total_reward = 0)\n",
    "            except IndexError:\n",
    "                print('Error: Out of bounds')\n",
    "                continue\n",
    " \n",
    "        # ^^REDUCE CLUSTER OF VARIBALES OUT\n",
    "        \n",
    "        \n",
    "        #if steps % 20 == 0 or done:\n",
    "            #print(\"observations:\", \" \".join([f\"{x:+0.2f}\" for x in s]))  # NEED TO RETURN S !\n",
    "            #print(f\"step {steps} total_reward {total_reward:+0.2f}\")\n",
    "        #steps += 1\n",
    "        \n",
    "        if done:\n",
    "            print('The total reward is:',total_reward)\n",
    "            break\n",
    "\n",
    "    return total_reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a18e50fe-43e2-4eb3-b550-0e60bc2642ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward=-3600.000 e= 361.236 power=12000.000\n",
      "Error: Out of bounds\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'done' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xb/n2_l2qn97hv_5qmbvkzjblzh0000gn/T/ipykernel_2027/648334379.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# running code:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#if __name__ == \"__main__\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdemo_heuristic_lander\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/xb/n2_l2qn97hv_5qmbvkzjblzh0000gn/T/ipykernel_2027/3178264144.py\u001b[0m in \u001b[0;36mdemo_heuristic_lander\u001b[0;34m(render)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#steps += 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The total reward is:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'done' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# running code:\n",
    "#if __name__ == \"__main__\":\n",
    "demo_heuristic_lander(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c0288-2dcf-454b-95e6-73cf1e98ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = \n",
    "\n",
    "angle = np.rad2deg(np.arctan(np.linalg.norm(V[:,0])/np.linalg.norm(V[:,1]))); # not sure at all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bfb613-dcd7-43b9-8aac-230fd580a20c",
   "metadata": {},
   "source": [
    "## Compare demo_heuristic and ML testing\n",
    "## Keep MINIMUM for quick testing purposes !\n",
    "\n",
    "#np.random.seed(122) # seed random number generator for reproducible results \n",
    "\n",
    "land, landing_site = mars_surface()\n",
    "\n",
    "#1. K_p= 50.000 ; K_h= 0.010 ; K_v= 0.010 ; K_i= 0.005 ; K_d= 75.001 ;\n",
    "K_p= 50.000 ; K_h= 0.001 ; K_v= 0.005 ; K_i= 0.005 ; K_d= 75.000\n",
    "\n",
    "OutofBounds= 0\n",
    "OutofFuel = 0\n",
    "trials = 0\n",
    "count = 0\n",
    "iterations = 5\n",
    "land_speed_results = np.zeros((iterations,2))\n",
    "fuel_results = np.zeros((iterations))\n",
    "\n",
    "for i in list(range(iterations)):\n",
    "    X0 = [randint(2000, 5000), randint(15000, 16000)] \n",
    "    V0 = [randint(-50,50), randint(-500,-300)]  \n",
    "    #V0[0] = 0 #when using seed() for better results and easier testing of parameters\n",
    "    try:\n",
    "        Xs, Vs, thrust, success,fuel_warning_printed, fuel, rotate, parachute = simulate(X0, V0, land, landing_site, dt=0.1, Nstep=3500, \n",
    "                                        autopilot=proportional_autopilot, fuel=400,parameters=[K_v,K_p,K_h,K_i,K_d],parachute=None)\n",
    "    except IndexError:\n",
    "        print('Error: Out of bounds')\n",
    "        OutofBounds += 1\n",
    "        land_speed_results[i, i] = np.inf\n",
    "        fuel_results[i, i] = np.inf\n",
    "        continue\n",
    "    land_speed_results[i,:] = (i,(Vs[-1,0:1]))  #  Vs[-1,1] is vertical and Vs[-1,0] is horizontal terminal velocity\n",
    "    fuel_results[i] = fuel\n",
    "    count += success\n",
    "    OutofFuel += fuel_warning_printed\n",
    "    trials += 1\n",
    "\n",
    "#assert count/trials > 0.95 # require 95% success rate \n",
    "\n",
    "print('Number of success (fuel remaining):',count)\n",
    "print('Number of Out of fuel:', OutofFuel)\n",
    "print('Number of Out of bound errors:', OutofBounds)\n",
    "print('Number of trials that ran without error:',trials)  \n",
    "print('Success percentage:',(count/(trials+OutofBounds))*100) #when not using seed\n",
    "\n",
    "print(land_speed_results)\n",
    "print(fuel_results)\n",
    "\n",
    "plot_lander(land, landing_site, Xs, thrust, animate=True, step=10)\n",
    "print('success rate:',(count/trials)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa9cb28-e83c-4ef3-8512-6ad09bc3ab98",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "    ML: Mars Lander\n",
    "    LL: Lunar Lander\n",
    "\n",
    " ##### Action Space\n",
    "    There are four discrete actions available: do nothing, fire left\n",
    "    orientation engine, fire main engine, fire right orientation engine.rotate\n",
    "    \n",
    "    if self.continuous:\n",
    "      Action is two floats [main engine, left-right engines] (only need 1 float !!)\n",
    "      Main engine: -1..0 off, 0..+1 throttle from 50% to 100% power. Engine can't work with less than 50% power.\n",
    "     (Don't need this: Left-right:  -1.0..-0.5 fire left engine, +0.5..+1.0 fire right engine, -0.5..0.5 off)\n",
    " ##### Observation Space\n",
    "    There are 8 states: the coordinates of the lander in `x` & `y`, its linear\n",
    "    velocities in `x` & `y`, its angle, its angular velocity, and two boleans\n",
    "    showing if each leg is in contact with the ground or not. more? parachute, fuel\n",
    " #### Rewards\n",
    "    Reward for moving from the top of the screen to the landing pad and zero\n",
    "    speed is about 100..140 points.\n",
    "    If the lander moves away from the landing (pad) zone it loses reward.\n",
    "    If the lander crashes, it receives an additional -100 points. If it comes\n",
    "    to rest, it receives an additional +100 points. \n",
    "    Firing the main engine is -0.3 points each frame. Solved is 200 points.\n",
    " #### Episode Termination\n",
    "     ....\n",
    " ### Notes\n",
    "     - Can probably get rid of: step function, self variable and env variable, seed , render\n",
    "     \n",
    "     - What is env? env = gym.make(\"LunarLander-v2\", continuous=True); if env.continuous: ; ... => ML always continous\n",
    "     - Seed? seed: Optional[int] = None, ; demo_heuristic_lander(env, seed=None, render=False):\n",
    "     - Info? def reset( ... return_info: bool = False, ; if not return_info:\n",
    "            return self.step(np.array([0, 0]) if self.continuous else 0)[0] (in reset def)  => can get rid of it\n",
    "     - Render? def render(self, mode=\"human\"): ... pygame.init()..self.screen = pygame.display.set_mode((VIEWPORT_W, VIEWPORT_H)).. self.clock =    pygame.time.Clock() => so related to the environment, get rid of it\n",
    "     - Self: no def, I think that self.[...] is a way of passing the variables between defs? + replace by 'lander' ?\n",
    "     class\n",
    "     - Action: can prob eliminate it, the action (power/thrust) is decided in the autopilot, and it's not directly related to the reward\n",
    "     \n",
    "Note about code adaptation: there is no middle ground; either I take some stuff from LL (rewards and states) and put them in ML, or I kind od adapt the LL with some aspects of the ML (keep LL graphics and env); \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6de37c-3cc7-4c40-8936-91ae84a805eb",
   "metadata": {},
   "source": [
    "## DRAFT of relevant functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9d0c9e-599e-4d12-b909-db42fbf3a078",
   "metadata": {},
   "source": [
    "# running code:\n",
    "if __name__ == \"__main__\":\n",
    "    demo_heuristic_lander(LunarLander(), render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d397e4-7552-4847-9af1-a99870fe38db",
   "metadata": {},
   "source": [
    "def step(self, action):\n",
    "        #if self.continuous:\n",
    "            action = np.clip(action, -1, +1).astype(np.float32)\n",
    "        #else:\n",
    "            #assert self.action_space.contains(\n",
    "                #action\n",
    "            #), f\"{action!r} ({type(action)}) invalid \"\n",
    "\n",
    "        # Engines # don't use side engines! only main engine\n",
    "        #tip = (math.sin(self.lander.angle), math.cos(self.lander.angle)) # what is tip??\n",
    "        #side = (-tip[1], tip[0])\n",
    "        #dispersion = [self.np_random.uniform(-1.0, +1.0) / SCALE for _ in range(2)]  #graphics?\n",
    "\n",
    "        m_power = 0.0       # from MAIN_ENGINE_POWER (= 13.0) at start of code # replace with ML equivalent\n",
    "        if (self.continuous and action[0] > 0.0) or (\n",
    "            not self.continuous and action == 2\n",
    "        ):\n",
    "            # Main engine\n",
    "            #if self.continuous:  # assume that always continuous?\n",
    "                m_power = (np.clip(action[0], 0.0, 1.0) + 1.0) * 0.5  # 0.5..1.0\n",
    "                assert m_power >= 0.5 and m_power <= 1.0\n",
    "            #else:\n",
    "                #m_power = 1.0   \n",
    "            ox = ( # movement in x direction ?\n",
    "                tip[0] * (4 / SCALE + 2 * dispersion[0]) + side[0] * dispersion[1]\n",
    "            )  # 4 is move a bit downwards, +-2 for randomness\n",
    "            oy = -tip[1] * (4 / SCALE + 2 * dispersion[0]) - side[1] * dispersion[1]\n",
    "            \n",
    "            impulse_pos = (self.lander.position[0] + ox, self.lander.position[1] + oy) # thrust equivalent??\n",
    "\n",
    "            self.lander.ApplyLinearImpulse(   #ApplyLinearImpulse from Box2D ; keep? only for graphics?\n",
    "                (-ox * MAIN_ENGINE_POWER * m_power, -oy * MAIN_ENGINE_POWER * m_power),\n",
    "                impulse_pos,\n",
    "                True,\n",
    "            )\n",
    "\n",
    "        #s_power = 0.0   #from SIDE_ENGINE_POWER (= 0.6) so deleted everthing that was below this in LL code\n",
    "\n",
    "        self.world.Step(1.0 / FPS, 6 * 30, 2 * 30) # ?? graphics??\n",
    "        \n",
    "        # FPS: frames per second?\n",
    " \n",
    "        pos = X # from ML simulate  #LL: self.lander.position\n",
    "        vel = V # from ML simulate  #LL: self.lander.linearVelocity\n",
    "        state = [\n",
    "            (pos.x - VIEWPORT_W / SCALE / 2) / (VIEWPORT_W / SCALE / 2),\n",
    "            (pos.y - (self.helipad_y + LEG_DOWN / SCALE)) / (VIEWPORT_H / SCALE / 2),\n",
    "            vel.x * (VIEWPORT_W / SCALE / 2) / FPS,  # velocity from distance / time calculation ?!\n",
    "            vel.y * (VIEWPORT_H / SCALE / 2) / FPS,\n",
    "            self.lander.angle,\n",
    "            20.0 * self.lander.angularVelocity / FPS,\n",
    "            #1.0 if self.legs[0].ground_contact else 0.0,  #don't want legs state 6 & 7\n",
    "            #1.0 if self.legs[1].ground_contact else 0.0,\n",
    "        ]\n",
    "        assert len(state) == 6  # was 8 in LL (but state 6 & 7 were ten points for legs contact)\n",
    "\n",
    "        reward = 0\n",
    "        shaping = (\n",
    "            -100 * np.sqrt(state[0] * state[0] + state[1] * state[1]) # Magnitude of position vectors\n",
    "            - 100 * np.sqrt(state[2] * state[2] + state[3] * state[3])  # Magnitude of velocity vectors\n",
    "            - 100 * abs(state[4])\n",
    "            #+ 10 * state[6]  # And ten points for legs contact\n",
    "            #+ 10 * state[7]\n",
    "        )  \n",
    "     \n",
    "        if self.prev_shaping is not None:\n",
    "            reward = shaping - self.prev_shaping\n",
    "        self.prev_shaping = shaping # ??\n",
    "\n",
    "        reward -= (\n",
    "            m_power * 0.30   # add ML fuel consumption               # replace from simulate\n",
    "        )  # less fuel spent is better, about -30 for heuristic landing\n",
    "\n",
    "        \n",
    "        done = False  #needed?\n",
    "        #if self.game_over or abs(state[0]) >= 1.0:\n",
    "            #done = True\n",
    "            reward = -100\n",
    "        #if not self.lander.awake:   # check this means succesful landing ?\n",
    "            #done = True\n",
    "            reward = +100\n",
    "        # ^^replace by simluation checks for crash or landind + attribute rewards from ML simulation:\n",
    "        # check for safe or crash landing\n",
    "        if X[1] < interpolate_surface(land, X[0]):\n",
    "            if not (land[landing_site, 0] <= X[0] and X[0] <= land[landing_site + 1, 0]):\n",
    "                print(\"crash! did not land on flat ground!\")\n",
    "                reward = -100\n",
    "            elif rotate != 0:\n",
    "                print(\"crash! did not land in a vertical position (tilt angle = 0 degrees)\")\n",
    "                reward = -100\n",
    "            elif abs(V[1]) >= 20: #was 40\n",
    "                print(\"crash! vertical speed must be limited (<20m/s in absolute value), got \", abs(V[1]))\n",
    "                reward = -100\n",
    "            elif abs(V[0]) >= 10: #was 20\n",
    "                print(\"crash! horizontal speed must be limited (<10m/s in absolute value), got \", abs(V[0]))\n",
    "                reward = -100\n",
    "            else:\n",
    "                print(\"safe landing - well done!\")\n",
    "                success = True\n",
    "                reward = +100\n",
    "            Nstep = i\n",
    "            break # keep or replace by 'done' from LL?\n",
    "        \n",
    "        # LL return, adapt to ML:\n",
    "        return np.array(state, dtype=np.float32), reward, done, {}\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5cbe58-ef18-4ba0-a783-19a5c839bea0",
   "metadata": {},
   "source": [
    "## LL: \n",
    "\n",
    "def heuristic(env, s):    # equivalent to autopilot? eliminate environment?\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        env: \n",
    "        s (list): The state. Attributes:\n",
    "                  s[0] is the horizontal coordinate\n",
    "                  s[1] is the vertical coordinate\n",
    "                  s[2] is the horizontal speed\n",
    "                  s[3] is the vertical speed\n",
    "                  s[4] is the angle\n",
    "                  s[5] is the angular speed \n",
    "                  (s[6] 1 if first leg has contact, else 0   => get rid of & s[7] 1 if second leg has contact, else 0  => get rid of)\n",
    "                  Could add extra states: fuel remaining\n",
    "    returns:\n",
    "         a: The heuristic to be fed into the step function defined above to determine the next step and reward.\n",
    "    \"\"\"\n",
    "\n",
    "    #angle_targ = s[0] * 0.5 + s[2] * 1.0  # angle should point towards center\n",
    "    #ML code:\n",
    "    h = height(land, X)\n",
    "    target = (land[landing_site+1, 0] + land[landing_site, 0]) // 2\n",
    "    dist = Xtarget-X[0]  #X[i,0], pass the histry of X (same for V)\n",
    "    rotate = np.rad2deg(np.arctan2(dist,h)) # change name to angle_targ ?\n",
    "\n",
    "    \n",
    "    if angle_targ > 0.4:\n",
    "        angle_targ = 0.4  # more than 0.4 radians (22 degrees) is bad\n",
    "    if angle_targ < -0.4:\n",
    "        angle_targ = -0.4\n",
    "    hover_targ = 0.55 * np.abs(     #related to vertical error??\n",
    "        s[0]\n",
    "    )  # target y should be proportional to horizontal offset\n",
    "\n",
    "    angle_todo = (angle_targ - s[4]) * 0.5 - (s[5]) * 1.0\n",
    "    hover_todo = (hover_targ - s[1]) * 0.5 - (s[3]) * 0.5\n",
    "\n",
    "    # assume that only continous possibility?\n",
    "    #if env.continuous:\n",
    "        a = np.array([hover_todo * 20 - 1, -angle_todo * 20])\n",
    "        a = np.clip(a, -1, +1) \n",
    "        #Action is two floats [main engine, left-right engines] (only need 1 float !!)\n",
    "        # side engines in charge of rotating! change by rotate?\n",
    "    \n",
    "    #else: # discrete\n",
    "        #a = 0      # action 1: do nothing\n",
    "        #if hover_todo > np.abs(angle_todo) and hover_todo > 0.05:\n",
    "            #a = 2  # action 3: fire main engine\n",
    "        #elif angle_todo < -0.05:\n",
    "            #a = 3  # action 4:fire right orientation engine\n",
    "        #elif angle_todo > +0.05:\n",
    "            #a = 1  # action 2:fire left orientation engine\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9788f1ce-d354-4627-9ece-13c3fb1b75d2",
   "metadata": {},
   "source": [
    "def demo_heuristic_lander(env, seed=None, render=False): # testing equivalent\n",
    "    total_reward = 0  #initialisation\n",
    "    steps = 0\n",
    "    #s = env.reset(seed=seed)  #Need to replace this by something from ML ?\n",
    "    while True:\n",
    "        a = heuristic(env, s)\n",
    "        s, r, done, info = env.step(a) # ??\n",
    "        total_reward += r\n",
    "\n",
    "        #if render:\n",
    "           # still_open = env.render()  #research what render is\n",
    "            #if still_open == False:\n",
    "               # break\n",
    "\n",
    "        if steps % 20 == 0 or done:\n",
    "            print(\"observations:\", \" \".join([f\"{x:+0.2f}\" for x in s]))\n",
    "            print(f\"step {steps} total_reward {total_reward:+0.2f}\")\n",
    "        steps += 1\n",
    "        if done:\n",
    "            break\n",
    "    #if render:\n",
    "        #env.close()\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf9eed-153c-4918-8254-35f5a4111aa1",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "- 'def render' refers to the graphic environment and clock of the 'pygame'\n",
    "- Env refers to continous or discrete? (From description: 'To use to the _continuous_ environment, you need to specify : env = gym.make(\"LunarLander-v2\", continuous=True)')\n",
    "- 'self.particles' & 'def _create_particle' : just a decoration, referes to small particles soming out of bottom of Lunar Lander in simulation\n",
    "- Box2D: A 2D physics engine for games\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9740df1d-fd56-4bfd-b186-a27999e48362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
